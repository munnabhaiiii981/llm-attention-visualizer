# LLM Attention Visualizer ğŸ”

Interactive tool for analyzing attention patterns in transformer models, helping understand how LLMs process different types of text inputs.

## Features
- ğŸ¯ Layer-wise attention visualization
- ğŸ”¥ Attention head heatmaps
- ğŸ“Š Token importance scoring
- ğŸ¨ Interactive plotly visualizations
- ğŸ“± Easy-to-use Streamlit interface

## Quick Start
```bash
pip install -r requirements.txt
streamlit run app.py
